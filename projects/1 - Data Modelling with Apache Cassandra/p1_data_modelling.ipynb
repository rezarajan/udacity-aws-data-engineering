{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\git\\personal\\udacity_aws_data_engineering\\projects\\1 - Data Modelling with Apache Cassandra\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "\n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Apache Cassandra Table Creation, Data Insertion and Query Validation\n",
    "\n",
    "The newly generated `event_datafile_new.csv` will be used to insert data into tables. The following fields are available:\n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Cassandra Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster\n",
    "*Note:* a Docker Compose file has been provided to easily spin-up a Cassandra cluster. Simply run `docker compose up -d`. On Windows, it is recommended to use Docker Desktop with the WSL backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyspace = 'project1'\n",
    "try:\n",
    "    query = f\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS {keyspace}\n",
    "    WITH replication = {{'class': 'SimpleStrategy', 'replication_factor' : 1}};\n",
    "    \"\"\"\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    session.set_keyspace(keyspace=keyspace)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Pandas Row Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom row factory\n",
    "def pandas_factory(colnames, rows):\n",
    "    return pd.DataFrame(rows, columns=colnames)\n",
    "\n",
    "# Set the row factory for Cassandra\n",
    "session.row_factory = pandas_factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for created tables\n",
    "tables = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tables to Run the Queries\n",
    "Since Apache Cassandra is a NoSQL database, we must first consider the queries to model the tables after.\n",
    "\n",
    "The following three questions are asked of the data:\n",
    "1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "Queries must first be templated for each question, and tables created following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1\n",
    "> Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "Since we are working with NoSQL, it is imperative to first consider the query to model against.\n",
    "\n",
    "In this case, the query would be structured follows:\n",
    "`SELECT artist, song, length from table_name WHERE sessionId = 338 AND itemInSession = 4;`\n",
    "\n",
    "Primary Key:\n",
    "As mandated by the WHERE clause, the data model must include sessionId and itemInSession in the primary key definition.\n",
    "Given that the combination of these two fields produce a unique value, they will be suitable candidates for the primary key.\n",
    "\n",
    "Data Types:\n",
    "By simple oberservation of the source data, we may infer some data types:\n",
    "\n",
    "Numerical:\n",
    "- sessionId (INT)\n",
    "- itemInSession (INT)\n",
    "- length (FLOAT)\n",
    "\n",
    "Integers are given to fields with small, whole numbers, while the float is assigned to length as it contains fractional parts.\n",
    "\n",
    "Non-Numerical:\n",
    "- artist (VARCHAR)\n",
    "- song (VARCHAR)\n",
    "\n",
    "These text-based fields utilize VARCHAR as it is a more standard data type to use, but the TEXT data type may have also been used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'music_history_by_session' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Model table after query requirements\n",
    "table_name = 'music_history_by_session';\n",
    "tables.append(table_name)\n",
    "\n",
    "drop_query = f'DROP TABLE IF EXISTS {table_name};'\n",
    "\n",
    "query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    sessionId INT,\n",
    "    itemInSession INT,\n",
    "    artist VARCHAR,\n",
    "    song VARCHAR,\n",
    "    length FLOAT,\n",
    "    PRIMARY KEY (sessionId, itemInSession)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(drop_query)\n",
    "    session.execute(query)\n",
    "    print(f\"Table '{table_name}' created successfully.\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f\"Error during table creation: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into the table\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "tmp = []\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.DictReader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for row in csvreader:\n",
    "        query = f\"\"\"\n",
    "            INSERT INTO {table_name} (sessionId, itemInSession, artist, song, length) \n",
    "            VALUES (%s, %s, %s, %s, %s);\n",
    "        \"\"\"\n",
    "        values = (int(row['sessionId']), int(row['itemInSession']), row['artist'], row['song'], float(row['length']))\n",
    "        try:\n",
    "            session.execute(query, values)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Faithless</td>\n",
       "      <td>Music Matters (Mark Knight Dub)</td>\n",
       "      <td>495.307312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist                             song      length\n",
       "0  Faithless  Music Matters (Mark Knight Dub)  495.307312"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the query results\n",
    "table_name = 'music_history_by_session'\n",
    "sessionId = 338\n",
    "itemInSession = 4\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT artist, song, length\n",
    "FROM {table_name}\n",
    "WHERE sessionId = {sessionId}\n",
    "AND itemInSession = {itemInSession};\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result_set = session.execute(query)\n",
    "    df = result_set._current_rows\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2\n",
    "> Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "Again, we must first consider the query to model the table against.\n",
    "\n",
    "In this case, the query would be structured follows:\n",
    "`SELECT artist, song, user from table_name WHERE userId = 10 AND sessionId = 182;`\n",
    "\n",
    "Primary Key:\n",
    "- As mandated by the WHERE clause, the data model must include userId and sessionId in the primary key definition.\n",
    "- In this case, we must also ensure that the song is sorted by itemInSession, and thus include it as a clustering column.\n",
    "- For performance reasons, it would make sense to create a composite partition key of userId and sessionId. In this way, sessions for the same user will be stored on the same node. In a testing environment the implications are negligible, but it is important to consider how the data will behave in a production environment\n",
    "\n",
    "Data Types:\n",
    "Building on the data types outlined in query 1, we extend the following:\n",
    "\n",
    "Numerical:\n",
    "- userId (INT)\n",
    "\n",
    "Non-Numerical:\n",
    "- user (VARCHAR)\n",
    "\n",
    "To note: the `user` field is a derived field from the `firstName` and `lastName` fields in the source data. Since these are both text-based, we assign a VARCHAR type to this new field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'music_history_by_user' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Model table after query requirements\n",
    "table_name = 'music_history_by_user';\n",
    "tables.append(table_name)\n",
    "\n",
    "drop_query = f'DROP TABLE IF EXISTS {table_name};'\n",
    "\n",
    "query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    userId INT,\n",
    "    sessionId INT,\n",
    "    itemInSession INT,\n",
    "    artist VARCHAR,\n",
    "    song VARCHAR,\n",
    "    user VARCHAR,\n",
    "    PRIMARY KEY ((userId, sessionId), itemInSession)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(drop_query)\n",
    "    session.execute(query)\n",
    "    print(f\"Table '{table_name}' created successfully.\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f\"Error during table creation: {e}\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into the table\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "tmp = []\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.DictReader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for row in csvreader:\n",
    "        query = f\"\"\"\n",
    "            INSERT INTO {table_name} (userId, sessionId, itemInSession, artist, song, user) \n",
    "            VALUES (%s, %s, %s, %s, %s, %s);\n",
    "        \"\"\"\n",
    "        values = (\n",
    "            int(row['userId']),\n",
    "            int(row['sessionId']),\n",
    "            int(row['itemInSession']),\n",
    "            row['artist'],\n",
    "            row['song'],\n",
    "            f\"{row['firstName']} {row['lastName']}\"\n",
    "        )\n",
    "        try:\n",
    "            session.execute(query, values)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Down To The Bone</td>\n",
       "      <td>Keep On Keepin' On</td>\n",
       "      <td>Sylvie Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Three Drives</td>\n",
       "      <td>Greece 2000</td>\n",
       "      <td>Sylvie Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sebastien Tellier</td>\n",
       "      <td>Kilometer</td>\n",
       "      <td>Sylvie Cruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lonnie Gordon</td>\n",
       "      <td>Catch You Baby (Steve Pitron &amp; Max Sanna Radio...</td>\n",
       "      <td>Sylvie Cruz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              artist                                               song  \\\n",
       "0   Down To The Bone                                 Keep On Keepin' On   \n",
       "1       Three Drives                                        Greece 2000   \n",
       "2  Sebastien Tellier                                          Kilometer   \n",
       "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
       "\n",
       "          user  \n",
       "0  Sylvie Cruz  \n",
       "1  Sylvie Cruz  \n",
       "2  Sylvie Cruz  \n",
       "3  Sylvie Cruz  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the query results\n",
    "table_name = 'music_history_by_user'\n",
    "userId = 10\n",
    "sessionId = 182\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT artist, song, user\n",
    "FROM {table_name}\n",
    "WHERE userId = {userId}\n",
    "AND sessionId = {sessionId};\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result_set = session.execute(query)\n",
    "    df = result_set._current_rows\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3\n",
    "> Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "In this case, the query would be structured follows:\n",
    "`SELECT user from table_name WHERE song = 'All Hands Against His Own;`\n",
    "\n",
    "Primary Key:\n",
    "- As mandated by the WHERE clause, the data model must at least include song in the primary key definition.\n",
    "- Since we are also selecting the user, although not in the WHERE clause, we must enforce uniqueness on the primary key by including either the user or userId field.\n",
    "- It would make the most sense to use the userId field in this case, in case of multiple users having the same name.\n",
    "- Thus, the song field is used as the partition key, and the userId field as the clustering column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'user_history_by_song' created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Model table after query requirements\n",
    "table_name = 'user_history_by_song';\n",
    "tables.append(table_name)\n",
    "\n",
    "drop_query = f'DROP TABLE IF EXISTS {table_name};'\n",
    "\n",
    "# Assume there is only one song, such that we do not need to specify the artist\n",
    "query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    song VARCHAR,\n",
    "    userId INT,\n",
    "    user VARCHAR,\n",
    "    PRIMARY KEY (song, userId)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    session.execute(drop_query)\n",
    "    session.execute(query)\n",
    "    print(f\"Table '{table_name}' created successfully.\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(f\"Error during table creation: {e}\")                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into the table\n",
    "file = 'event_datafile_new.csv'\n",
    "\n",
    "tmp = []\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.DictReader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for row in csvreader:\n",
    "        query = f\"\"\"\n",
    "            INSERT INTO {table_name} (song, userId, user) \n",
    "            VALUES (%s, %s, %s);\n",
    "        \"\"\"\n",
    "        values = (\n",
    "            row['song'],\n",
    "            int(row['userId']),\n",
    "            f\"{row['firstName']} {row['lastName']}\"\n",
    "        )\n",
    "        try:\n",
    "            session.execute(query, values)\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jacqueline Lynch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tegan Levine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sara Johnson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               user\n",
       "0  Jacqueline Lynch\n",
       "1      Tegan Levine\n",
       "2      Sara Johnson"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the query results\n",
    "table_name = 'user_history_by_song'\n",
    "song = 'All Hands Against His Own'\n",
    "\n",
    "query = f\"\"\"\n",
    "SELECT user\n",
    "FROM {table_name}\n",
    "WHERE song = '{song}';\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    result_set = session.execute(query)\n",
    "    df = result_set._current_rows\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 'music_history_by_session' dropped successfully.\n",
      "Table 'music_history_by_user' dropped successfully.\n",
      "Table 'user_history_by_song' dropped successfully.\n"
     ]
    }
   ],
   "source": [
    "## TO-DO: Drop the table before closing out the sessions\n",
    "for table in tables:\n",
    "    query = f'DROP TABLE IF EXISTS {table};'\n",
    "    try:\n",
    "        session.execute(query)\n",
    "        print(f\"Table '{table}' dropped successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during table drop: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
